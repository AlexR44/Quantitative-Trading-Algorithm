{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8905827f-ad2a-4067-997c-953c35c19189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: postgres@securities_master_interday'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import requests\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from dotenv import load_dotenv\n",
    "import typing\n",
    "import fmpsdk\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "# Connecting to API\n",
    "# Loading API key\n",
    "load_dotenv(\"master_api.env\")\n",
    "apikey = os.getenv(\"fmpsdk_api_key\")\n",
    "\n",
    "# Obtain a database connection to the database instance\n",
    "conn = psycopg2.connect(\"dbname=securities_master_interday user=postgres host=localhost password=postgres port=5432\")\n",
    "engine = create_engine(\"postgresql://postgres:postgres@localhost:5432/securities_master_interday\")\n",
    "# Checking connection\n",
    "session=sessionmaker(bind=engine)()\n",
    "%load_ext sql\n",
    "%sql $engine.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddfddb61-caa1-43d0-85b6-f549bfbd16a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_list_of_db_tickers():\n",
    "    \"\"\"\n",
    "    Obtains a list of the ticker symbols in the database.\n",
    "    \"\"\"\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT id, ticker FROM symbol\")\n",
    "    conn.commit()\n",
    "    data = cur.fetchall()\n",
    "    return [(d[0], d[1]) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45821faa-a716-4978-8c89-19aa74a5071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_data(symbol,from_date,to_date):\n",
    "    import pandas as pd\n",
    "\n",
    "    #populating URL\n",
    "    api_url = (f\"https://financialmodelingprep.com/api/v3/historical-price-full/{symbol}\"\n",
    "               f\"?from={from_date}&to={to_date}&apikey={apikey}\")\n",
    "    #Fetching data\n",
    "    try:\n",
    "        stock_data_fetch=requests.get(api_url)\n",
    "        stock_data= stock_data_fetch.json()\n",
    "        stock_data_df = pd.DataFrame(stock_data['historical'])\n",
    "        stock_data_df=stock_data_df.set_index('date',drop=True)\n",
    "    except Exception as e:\n",
    "        print('Could not download data for %s ticker \"(%s)...skipping.' % (symbol, e))\n",
    "        return []\n",
    "    else:\n",
    "        #creating dataframe\n",
    "        prices=stock_data['historical']\n",
    "        prices2=[]\n",
    "        \n",
    "        for i in prices:\n",
    "            #print(i['date'])\n",
    "            #bar = i.keys()\n",
    "            prices2.append(\n",
    "                (\n",
    "                    i['date'],\n",
    "                    float(i['open']),\n",
    "                    float(i['high']),\n",
    "                    float(i['low']),\n",
    "                    float(i['close']),\n",
    "                    int(i['volume']),\n",
    "                    float(i['adjClose'])))            \n",
    "        return prices2\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41bd36d2-6ce4-45d1-a777-42259eafbb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2024-01-26', 152.87, 154.11, 152.8, 153.79, 19578858, 153.79),\n",
       " ('2024-01-25', 151.74, 154.76, 151.22, 153.64, 21495120, 153.64),\n",
       " ('2024-01-24', 150.29, 151.57, 149.84, 150.35, 19245031, 150.35)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test -- Obtain data up to today's date\n",
    "from datetime import date\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "today = date.today()-DateOffset(days=1)\n",
    "to=today-DateOffset(days=4)\n",
    "from_date=to.strftime(\"%Y-%m-%d\")\n",
    "to_date=today.strftime(\"%Y-%m-%d\")\n",
    "to_date=today.strftime(\"%Y-%m-%d\")\n",
    "#from_date='2019-12-03'\n",
    "#2021-10-08\n",
    "#2019-12-03\n",
    "stock_data('GOOG',from_date,to_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ea88c4-2b61-470d-8a47-fd03b9971a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_daily_data_into_db(symbol_id, daily_data):\n",
    "    \"\"\"\n",
    "    Takes a list of tuples of daily data and adds it to the\n",
    "     database. Appends the vendor ID and symbol ID to the data.\n",
    "    \"\"\"   \n",
    "    now = dt.utcnow()\n",
    "    \n",
    "    # Amend the data to include the vendor ID and symbol ID\n",
    "    daily_data = [\n",
    "    (symbol_id, d[0], now, now,\n",
    "    d[1], d[2], d[3], d[4], d[5], d[6])\n",
    "    for d in daily_data\n",
    "    ]\n",
    "    # Create the insert strings\n",
    "    column_str = (\n",
    "    \"symbol_id, price_date, created_date, \"\n",
    "    \"last_updated_date, open_price, high_price, low_price, \"\n",
    "    \"close_price, volume, adj_close_price\"\n",
    "    )\n",
    "    insert_str = (\"%s, \" * 10)[:-2]\n",
    "    final_str = ( \"INSERT INTO daily_price (%s) VALUES (%s);\" % (column_str, insert_str))\n",
    "    \n",
    "    # Using the SQL connection, carry out an INSERT INTO for every symbol\n",
    "    cur = conn.cursor()\n",
    "    cur.executemany(final_str, daily_data)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc3eac90-9c2a-4fc6-af79-2feb2f913a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clears data from existing table to avoid conflicts\n",
    "#cur = conn.cursor()\n",
    "#cur.execute(\"DELETE FROM daily_price\")\n",
    "#conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dca36444-14c0-4ddf-9e6a-22d893904877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding data for MMM: 1 out of 740\n",
      "Adding data for AOS: 2 out of 740\n",
      "Adding data for ABT: 3 out of 740\n",
      "Adding data for ABBV: 4 out of 740\n",
      "Adding data for ACN: 5 out of 740\n",
      "Adding data for ATVI: 6 out of 740\n",
      "Could not download data for ATVI ticker \"('historical')...skipping.\n",
      "Adding data for ADM: 7 out of 740\n",
      "Adding data for ADBE: 8 out of 740\n",
      "Adding data for ADP: 9 out of 740\n",
      "Adding data for AAP: 10 out of 740\n",
      "Adding data for AES: 11 out of 740\n",
      "Adding data for AFL: 12 out of 740\n",
      "Adding data for A: 13 out of 740\n",
      "Adding data for APD: 14 out of 740\n",
      "Adding data for AKAM: 15 out of 740\n",
      "Adding data for ALK: 16 out of 740\n",
      "Adding data for ALB: 17 out of 740\n",
      "Adding data for ARE: 18 out of 740\n",
      "Adding data for ALGN: 19 out of 740\n",
      "Adding data for ALLE: 20 out of 740\n",
      "Adding data for LNT: 21 out of 740\n",
      "Adding data for ALL: 22 out of 740\n",
      "Adding data for GOOGL: 23 out of 740\n",
      "Adding data for GOOG: 24 out of 740\n",
      "Adding data for MO: 25 out of 740\n",
      "Adding data for AMZN: 26 out of 740\n",
      "Adding data for AMCR: 27 out of 740\n",
      "Adding data for AMD: 28 out of 740\n",
      "Adding data for AEE: 29 out of 740\n",
      "Adding data for AAL: 30 out of 740\n",
      "Adding data for AEP: 31 out of 740\n",
      "Adding data for AXP: 32 out of 740\n",
      "Adding data for AIG: 33 out of 740\n",
      "Adding data for AMT: 34 out of 740\n",
      "Adding data for AWK: 35 out of 740\n",
      "Adding data for AMP: 36 out of 740\n",
      "Adding data for ABC: 37 out of 740\n",
      "Could not download data for ABC ticker \"('historical')...skipping.\n",
      "Adding data for AME: 38 out of 740\n",
      "Adding data for AMGN: 39 out of 740\n",
      "Adding data for APH: 40 out of 740\n",
      "Adding data for ADI: 41 out of 740\n",
      "Adding data for ANSS: 42 out of 740\n",
      "Adding data for AON: 43 out of 740\n",
      "Adding data for APA: 44 out of 740\n",
      "Adding data for AAPL: 45 out of 740\n",
      "Adding data for AMAT: 46 out of 740\n",
      "Adding data for APTV: 47 out of 740\n",
      "Adding data for ACGL: 48 out of 740\n",
      "Adding data for ANET: 49 out of 740\n",
      "Adding data for AJG: 50 out of 740\n",
      "Adding data for AIZ: 51 out of 740\n",
      "Adding data for T: 52 out of 740\n",
      "Adding data for ATO: 53 out of 740\n",
      "Adding data for ADSK: 54 out of 740\n",
      "Adding data for AZO: 55 out of 740\n",
      "Adding data for AVB: 56 out of 740\n",
      "Adding data for AVY: 57 out of 740\n",
      "Adding data for BKR: 58 out of 740\n",
      "Adding data for BALL: 59 out of 740\n",
      "Adding data for BAC: 60 out of 740\n",
      "Adding data for BBWI: 61 out of 740\n",
      "Adding data for BAX: 62 out of 740\n",
      "Adding data for BDX: 63 out of 740\n",
      "Adding data for WRB: 64 out of 740\n",
      "Adding data for BRK.B: 65 out of 740\n",
      "Adding data for BBY: 66 out of 740\n",
      "Adding data for BIO: 67 out of 740\n",
      "Adding data for TECH: 68 out of 740\n",
      "Adding data for BIIB: 69 out of 740\n",
      "Adding data for BLK: 70 out of 740\n",
      "Adding data for BK: 71 out of 740\n",
      "Adding data for BA: 72 out of 740\n",
      "Adding data for BKNG: 73 out of 740\n",
      "Adding data for BWA: 74 out of 740\n",
      "Adding data for BXP: 75 out of 740\n",
      "Adding data for BSX: 76 out of 740\n",
      "Adding data for BMY: 77 out of 740\n",
      "Adding data for AVGO: 78 out of 740\n",
      "Adding data for BR: 79 out of 740\n",
      "Adding data for BRO: 80 out of 740\n",
      "Adding data for BF.B: 81 out of 740\n",
      "Could not download data for BF.B ticker \"('historical')...skipping.\n",
      "Adding data for BG: 82 out of 740\n",
      "Adding data for CHRW: 83 out of 740\n",
      "Adding data for CDNS: 84 out of 740\n",
      "Adding data for CZR: 85 out of 740\n",
      "Adding data for CPT: 86 out of 740\n",
      "Adding data for CPB: 87 out of 740\n",
      "Adding data for COF: 88 out of 740\n",
      "Adding data for CAH: 89 out of 740\n",
      "Adding data for KMX: 90 out of 740\n",
      "Adding data for CCL: 91 out of 740\n",
      "Adding data for CARR: 92 out of 740\n",
      "Adding data for CTLT: 93 out of 740\n",
      "Adding data for CAT: 94 out of 740\n",
      "Adding data for CBOE: 95 out of 740\n",
      "Adding data for CBRE: 96 out of 740\n",
      "Adding data for CDW: 97 out of 740\n",
      "Adding data for CE: 98 out of 740\n",
      "Adding data for CNC: 99 out of 740\n",
      "Adding data for CNP: 100 out of 740\n",
      "Adding data for CDAY: 101 out of 740\n",
      "Adding data for CF: 102 out of 740\n",
      "Adding data for CRL: 103 out of 740\n",
      "Adding data for SCHW: 104 out of 740\n",
      "Adding data for CHTR: 105 out of 740\n",
      "Adding data for CVX: 106 out of 740\n",
      "Adding data for CMG: 107 out of 740\n",
      "Adding data for CB: 108 out of 740\n",
      "Adding data for CHD: 109 out of 740\n",
      "Adding data for CI: 110 out of 740\n",
      "Adding data for CINF: 111 out of 740\n",
      "Adding data for CTAS: 112 out of 740\n",
      "Adding data for CSCO: 113 out of 740\n",
      "Adding data for C: 114 out of 740\n",
      "Adding data for CFG: 115 out of 740\n",
      "Adding data for CLX: 116 out of 740\n",
      "Adding data for CME: 117 out of 740\n",
      "Adding data for CMS: 118 out of 740\n",
      "Adding data for KO: 119 out of 740\n",
      "Adding data for CTSH: 120 out of 740\n",
      "Adding data for CL: 121 out of 740\n",
      "Adding data for CMCSA: 122 out of 740\n",
      "Adding data for CMA: 123 out of 740\n",
      "Adding data for CAG: 124 out of 740\n",
      "Adding data for COP: 125 out of 740\n",
      "Adding data for ED: 126 out of 740\n",
      "Adding data for STZ: 127 out of 740\n",
      "Adding data for CEG: 128 out of 740\n",
      "Adding data for COO: 129 out of 740\n",
      "Adding data for CPRT: 130 out of 740\n",
      "Adding data for GLW: 131 out of 740\n",
      "Adding data for CTVA: 132 out of 740\n",
      "Adding data for CSGP: 133 out of 740\n",
      "Adding data for COST: 134 out of 740\n",
      "Adding data for CTRA: 135 out of 740\n",
      "Adding data for CCI: 136 out of 740\n",
      "Adding data for CSX: 137 out of 740\n",
      "Adding data for CMI: 138 out of 740\n",
      "Adding data for CVS: 139 out of 740\n",
      "Adding data for DHI: 140 out of 740\n",
      "Adding data for DHR: 141 out of 740\n",
      "Adding data for DRI: 142 out of 740\n",
      "Adding data for DVA: 143 out of 740\n",
      "Adding data for DE: 144 out of 740\n",
      "Adding data for DAL: 145 out of 740\n",
      "Adding data for XRAY: 146 out of 740\n",
      "Adding data for DVN: 147 out of 740\n",
      "Adding data for DXCM: 148 out of 740\n",
      "Adding data for FANG: 149 out of 740\n",
      "Adding data for DLR: 150 out of 740\n",
      "Adding data for DFS: 151 out of 740\n",
      "Adding data for DISH: 152 out of 740\n",
      "Could not download data for DISH ticker \"('historical')...skipping.\n",
      "Adding data for DIS: 153 out of 740\n",
      "Adding data for DG: 154 out of 740\n",
      "Adding data for DLTR: 155 out of 740\n",
      "Adding data for D: 156 out of 740\n",
      "Adding data for DPZ: 157 out of 740\n",
      "Adding data for DOV: 158 out of 740\n",
      "Adding data for DOW: 159 out of 740\n",
      "Adding data for DTE: 160 out of 740\n",
      "Adding data for DUK: 161 out of 740\n",
      "Adding data for DD: 162 out of 740\n",
      "Adding data for DXC: 163 out of 740\n",
      "Adding data for EMN: 164 out of 740\n",
      "Adding data for ETN: 165 out of 740\n",
      "Adding data for EBAY: 166 out of 740\n",
      "Adding data for ECL: 167 out of 740\n",
      "Adding data for EIX: 168 out of 740\n",
      "Adding data for EW: 169 out of 740\n",
      "Adding data for EA: 170 out of 740\n",
      "Adding data for ELV: 171 out of 740\n",
      "Adding data for LLY: 172 out of 740\n",
      "Adding data for EMR: 173 out of 740\n",
      "Adding data for ENPH: 174 out of 740\n",
      "Adding data for ETR: 175 out of 740\n",
      "Adding data for EOG: 176 out of 740\n",
      "Adding data for EPAM: 177 out of 740\n",
      "Adding data for EQT: 178 out of 740\n",
      "Adding data for EFX: 179 out of 740\n",
      "Adding data for EQIX: 180 out of 740\n",
      "Adding data for EQR: 181 out of 740\n",
      "Adding data for ESS: 182 out of 740\n",
      "Adding data for EL: 183 out of 740\n",
      "Adding data for ETSY: 184 out of 740\n",
      "Adding data for RE: 185 out of 740\n",
      "Could not download data for RE ticker \"('historical')...skipping.\n",
      "Adding data for EVRG: 186 out of 740\n",
      "Adding data for ES: 187 out of 740\n",
      "Adding data for EXC: 188 out of 740\n",
      "Adding data for EXPE: 189 out of 740\n",
      "Adding data for EXPD: 190 out of 740\n",
      "Adding data for EXR: 191 out of 740\n",
      "Adding data for XOM: 192 out of 740\n",
      "Adding data for FFIV: 193 out of 740\n",
      "Adding data for FDS: 194 out of 740\n",
      "Adding data for FAST: 195 out of 740\n",
      "Adding data for FRT: 196 out of 740\n",
      "Adding data for FDX: 197 out of 740\n",
      "Adding data for FITB: 198 out of 740\n",
      "Adding data for FRC: 199 out of 740\n",
      "Could not download data for FRC ticker \"('historical')...skipping.\n",
      "Adding data for FSLR: 200 out of 740\n",
      "Adding data for FE: 201 out of 740\n",
      "Adding data for FIS: 202 out of 740\n",
      "Adding data for FISV: 203 out of 740\n",
      "Could not download data for FISV ticker \"('historical')...skipping.\n",
      "Adding data for FLT: 204 out of 740\n",
      "Adding data for FMC: 205 out of 740\n",
      "Adding data for F: 206 out of 740\n",
      "Adding data for FTNT: 207 out of 740\n",
      "Adding data for FTV: 208 out of 740\n",
      "Adding data for FOXA: 209 out of 740\n",
      "Adding data for FOX: 210 out of 740\n",
      "Adding data for BEN: 211 out of 740\n",
      "Adding data for FCX: 212 out of 740\n",
      "Adding data for GRMN: 213 out of 740\n",
      "Adding data for IT: 214 out of 740\n",
      "Adding data for GEHC: 215 out of 740\n",
      "Adding data for GEN: 216 out of 740\n",
      "Adding data for GNRC: 217 out of 740\n",
      "Adding data for GD: 218 out of 740\n",
      "Adding data for GE: 219 out of 740\n",
      "Adding data for GIS: 220 out of 740\n",
      "Adding data for GM: 221 out of 740\n",
      "Adding data for GPC: 222 out of 740\n",
      "Adding data for GILD: 223 out of 740\n",
      "Adding data for GL: 224 out of 740\n",
      "Adding data for GPN: 225 out of 740\n",
      "Adding data for GS: 226 out of 740\n",
      "Adding data for HAL: 227 out of 740\n",
      "Adding data for HIG: 228 out of 740\n",
      "Adding data for HAS: 229 out of 740\n",
      "Adding data for HCA: 230 out of 740\n",
      "Adding data for PEAK: 231 out of 740\n",
      "Adding data for HSIC: 232 out of 740\n",
      "Adding data for HSY: 233 out of 740\n",
      "Adding data for HES: 234 out of 740\n",
      "Adding data for HPE: 235 out of 740\n",
      "Adding data for HLT: 236 out of 740\n",
      "Adding data for HOLX: 237 out of 740\n",
      "Adding data for HD: 238 out of 740\n",
      "Adding data for HON: 239 out of 740\n",
      "Adding data for HRL: 240 out of 740\n",
      "Adding data for HST: 241 out of 740\n",
      "Adding data for HWM: 242 out of 740\n",
      "Adding data for HPQ: 243 out of 740\n",
      "Adding data for HUM: 244 out of 740\n",
      "Adding data for HBAN: 245 out of 740\n",
      "Adding data for HII: 246 out of 740\n",
      "Adding data for IBM: 247 out of 740\n",
      "Adding data for IEX: 248 out of 740\n",
      "Adding data for IDXX: 249 out of 740\n",
      "Adding data for ITW: 250 out of 740\n",
      "Adding data for ILMN: 251 out of 740\n",
      "Adding data for INCY: 252 out of 740\n",
      "Adding data for IR: 253 out of 740\n",
      "Adding data for PODD: 254 out of 740\n",
      "Adding data for INTC: 255 out of 740\n",
      "Adding data for ICE: 256 out of 740\n",
      "Adding data for IFF: 257 out of 740\n",
      "Adding data for IP: 258 out of 740\n",
      "Adding data for IPG: 259 out of 740\n",
      "Adding data for INTU: 260 out of 740\n",
      "Adding data for ISRG: 261 out of 740\n",
      "Adding data for IVZ: 262 out of 740\n",
      "Adding data for INVH: 263 out of 740\n",
      "Adding data for IQV: 264 out of 740\n",
      "Adding data for IRM: 265 out of 740\n",
      "Adding data for JBHT: 266 out of 740\n",
      "Adding data for JKHY: 267 out of 740\n",
      "Adding data for J: 268 out of 740\n",
      "Adding data for JNJ: 269 out of 740\n",
      "Adding data for JCI: 270 out of 740\n",
      "Adding data for JPM: 271 out of 740\n",
      "Adding data for JNPR: 272 out of 740\n",
      "Adding data for K: 273 out of 740\n",
      "Adding data for KDP: 274 out of 740\n",
      "Adding data for KEY: 275 out of 740\n",
      "Adding data for KEYS: 276 out of 740\n",
      "Adding data for KMB: 277 out of 740\n",
      "Adding data for KIM: 278 out of 740\n",
      "Adding data for KMI: 279 out of 740\n",
      "Adding data for KLAC: 280 out of 740\n",
      "Adding data for KHC: 281 out of 740\n",
      "Adding data for KR: 282 out of 740\n",
      "Adding data for LHX: 283 out of 740\n",
      "Adding data for LH: 284 out of 740\n",
      "Adding data for LRCX: 285 out of 740\n",
      "Adding data for LW: 286 out of 740\n",
      "Adding data for LVS: 287 out of 740\n",
      "Adding data for LDOS: 288 out of 740\n",
      "Adding data for LEN: 289 out of 740\n",
      "Adding data for LNC: 290 out of 740\n",
      "Adding data for LIN: 291 out of 740\n",
      "Adding data for LYV: 292 out of 740\n",
      "Adding data for LKQ: 293 out of 740\n",
      "Adding data for LMT: 294 out of 740\n",
      "Adding data for PAYC: 295 out of 740\n",
      "Adding data for L: 296 out of 740\n",
      "Adding data for LOW: 297 out of 740\n",
      "Adding data for LUMN: 298 out of 740\n",
      "Adding data for LYB: 299 out of 740\n",
      "Adding data for MTB: 300 out of 740\n",
      "Adding data for MRO: 301 out of 740\n",
      "Adding data for MPC: 302 out of 740\n",
      "Adding data for MKTX: 303 out of 740\n",
      "Adding data for MAR: 304 out of 740\n",
      "Adding data for MMC: 305 out of 740\n",
      "Adding data for MLM: 306 out of 740\n",
      "Adding data for MAS: 307 out of 740\n",
      "Adding data for MA: 308 out of 740\n",
      "Adding data for MTCH: 309 out of 740\n",
      "Adding data for MKC: 310 out of 740\n",
      "Adding data for MCD: 311 out of 740\n",
      "Adding data for MCK: 312 out of 740\n",
      "Adding data for MDT: 313 out of 740\n",
      "Adding data for MRK: 314 out of 740\n",
      "Adding data for META: 315 out of 740\n",
      "Adding data for MET: 316 out of 740\n",
      "Adding data for MTD: 317 out of 740\n",
      "Adding data for MGM: 318 out of 740\n",
      "Adding data for MCHP: 319 out of 740\n",
      "Adding data for MU: 320 out of 740\n",
      "Adding data for MSFT: 321 out of 740\n",
      "Adding data for MAA: 322 out of 740\n",
      "Adding data for MRNA: 323 out of 740\n",
      "Adding data for MHK: 324 out of 740\n",
      "Adding data for MOH: 325 out of 740\n",
      "Adding data for TAP: 326 out of 740\n",
      "Adding data for MDLZ: 327 out of 740\n",
      "Adding data for MPWR: 328 out of 740\n",
      "Adding data for MNST: 329 out of 740\n",
      "Adding data for MCO: 330 out of 740\n",
      "Adding data for MS: 331 out of 740\n",
      "Adding data for MOS: 332 out of 740\n",
      "Adding data for MSI: 333 out of 740\n",
      "Adding data for MSCI: 334 out of 740\n",
      "Adding data for NDAQ: 335 out of 740\n",
      "Adding data for NTAP: 336 out of 740\n",
      "Adding data for NFLX: 337 out of 740\n",
      "Adding data for NWL: 338 out of 740\n",
      "Adding data for NEM: 339 out of 740\n",
      "Adding data for NWSA: 340 out of 740\n",
      "Adding data for NWS: 341 out of 740\n",
      "Adding data for NEE: 342 out of 740\n",
      "Adding data for NKE: 343 out of 740\n",
      "Adding data for NI: 344 out of 740\n",
      "Adding data for NDSN: 345 out of 740\n",
      "Adding data for NSC: 346 out of 740\n",
      "Adding data for NTRS: 347 out of 740\n",
      "Adding data for NOC: 348 out of 740\n",
      "Adding data for NCLH: 349 out of 740\n",
      "Adding data for NRG: 350 out of 740\n",
      "Adding data for NUE: 351 out of 740\n",
      "Adding data for NVDA: 352 out of 740\n",
      "Adding data for NVR: 353 out of 740\n",
      "Adding data for NXPI: 354 out of 740\n",
      "Adding data for ORLY: 355 out of 740\n",
      "Adding data for OXY: 356 out of 740\n",
      "Adding data for ODFL: 357 out of 740\n",
      "Adding data for OMC: 358 out of 740\n",
      "Adding data for ON: 359 out of 740\n",
      "Adding data for OKE: 360 out of 740\n",
      "Adding data for ORCL: 361 out of 740\n",
      "Adding data for OGN: 362 out of 740\n",
      "Adding data for OTIS: 363 out of 740\n",
      "Adding data for PCAR: 364 out of 740\n",
      "Adding data for PKG: 365 out of 740\n",
      "Adding data for PARA: 366 out of 740\n",
      "Adding data for PH: 367 out of 740\n",
      "Adding data for PAYX: 368 out of 740\n",
      "Adding data for PYPL: 369 out of 740\n",
      "Adding data for PNR: 370 out of 740\n",
      "Adding data for PEP: 371 out of 740\n",
      "Adding data for PKI: 372 out of 740\n",
      "Could not download data for PKI ticker \"('historical')...skipping.\n",
      "Adding data for PFE: 373 out of 740\n",
      "Adding data for PCG: 374 out of 740\n",
      "Adding data for PM: 375 out of 740\n",
      "Adding data for PSX: 376 out of 740\n",
      "Adding data for PNW: 377 out of 740\n",
      "Adding data for PXD: 378 out of 740\n",
      "Adding data for PNC: 379 out of 740\n",
      "Adding data for POOL: 380 out of 740\n",
      "Adding data for PPG: 381 out of 740\n",
      "Adding data for PPL: 382 out of 740\n",
      "Adding data for PFG: 383 out of 740\n",
      "Adding data for PG: 384 out of 740\n",
      "Adding data for PGR: 385 out of 740\n",
      "Adding data for PLD: 386 out of 740\n",
      "Adding data for PRU: 387 out of 740\n",
      "Adding data for PEG: 388 out of 740\n",
      "Adding data for PTC: 389 out of 740\n",
      "Adding data for PSA: 390 out of 740\n",
      "Adding data for PHM: 391 out of 740\n",
      "Adding data for QRVO: 392 out of 740\n",
      "Adding data for PWR: 393 out of 740\n",
      "Adding data for QCOM: 394 out of 740\n",
      "Adding data for DGX: 395 out of 740\n",
      "Adding data for RL: 396 out of 740\n",
      "Adding data for RJF: 397 out of 740\n",
      "Adding data for RTX: 398 out of 740\n",
      "Adding data for O: 399 out of 740\n",
      "Adding data for REG: 400 out of 740\n",
      "Adding data for REGN: 401 out of 740\n",
      "Adding data for RF: 402 out of 740\n",
      "Adding data for RSG: 403 out of 740\n",
      "Adding data for RMD: 404 out of 740\n",
      "Adding data for RHI: 405 out of 740\n",
      "Adding data for ROK: 406 out of 740\n",
      "Adding data for ROL: 407 out of 740\n",
      "Adding data for ROP: 408 out of 740\n",
      "Adding data for ROST: 409 out of 740\n",
      "Adding data for RCL: 410 out of 740\n",
      "Adding data for SPGI: 411 out of 740\n",
      "Adding data for CRM: 412 out of 740\n",
      "Adding data for SBAC: 413 out of 740\n",
      "Adding data for SLB: 414 out of 740\n",
      "Adding data for STX: 415 out of 740\n",
      "Adding data for SEE: 416 out of 740\n",
      "Adding data for SRE: 417 out of 740\n",
      "Adding data for NOW: 418 out of 740\n",
      "Adding data for SHW: 419 out of 740\n",
      "Adding data for SPG: 420 out of 740\n",
      "Adding data for SWKS: 421 out of 740\n",
      "Adding data for SJM: 422 out of 740\n",
      "Adding data for SNA: 423 out of 740\n",
      "Adding data for SEDG: 424 out of 740\n",
      "Adding data for SO: 425 out of 740\n",
      "Adding data for LUV: 426 out of 740\n",
      "Adding data for SWK: 427 out of 740\n",
      "Adding data for SBUX: 428 out of 740\n",
      "Adding data for STT: 429 out of 740\n",
      "Adding data for STLD: 430 out of 740\n",
      "Adding data for STE: 431 out of 740\n",
      "Adding data for SYK: 432 out of 740\n",
      "Adding data for SYF: 433 out of 740\n",
      "Adding data for SNPS: 434 out of 740\n",
      "Adding data for SYY: 435 out of 740\n",
      "Adding data for TMUS: 436 out of 740\n",
      "Adding data for TROW: 437 out of 740\n",
      "Adding data for TTWO: 438 out of 740\n",
      "Adding data for TPR: 439 out of 740\n",
      "Adding data for TRGP: 440 out of 740\n",
      "Adding data for TGT: 441 out of 740\n",
      "Adding data for TEL: 442 out of 740\n",
      "Adding data for TDY: 443 out of 740\n",
      "Adding data for TFX: 444 out of 740\n",
      "Adding data for TER: 445 out of 740\n",
      "Adding data for TSLA: 446 out of 740\n",
      "Adding data for TXN: 447 out of 740\n",
      "Adding data for TXT: 448 out of 740\n",
      "Adding data for TMO: 449 out of 740\n",
      "Adding data for TJX: 450 out of 740\n",
      "Adding data for TSCO: 451 out of 740\n",
      "Adding data for TT: 452 out of 740\n",
      "Adding data for TDG: 453 out of 740\n",
      "Adding data for TRV: 454 out of 740\n",
      "Adding data for TRMB: 455 out of 740\n",
      "Adding data for TFC: 456 out of 740\n",
      "Adding data for TYL: 457 out of 740\n",
      "Adding data for TSN: 458 out of 740\n",
      "Adding data for USB: 459 out of 740\n",
      "Adding data for UDR: 460 out of 740\n",
      "Adding data for ULTA: 461 out of 740\n",
      "Adding data for UNP: 462 out of 740\n",
      "Adding data for UAL: 463 out of 740\n",
      "Adding data for UPS: 464 out of 740\n",
      "Adding data for URI: 465 out of 740\n",
      "Adding data for UNH: 466 out of 740\n",
      "Adding data for UHS: 467 out of 740\n",
      "Adding data for VLO: 468 out of 740\n",
      "Adding data for VTR: 469 out of 740\n",
      "Adding data for VRSN: 470 out of 740\n",
      "Adding data for VRSK: 471 out of 740\n",
      "Adding data for VZ: 472 out of 740\n",
      "Adding data for VRTX: 473 out of 740\n",
      "Adding data for VFC: 474 out of 740\n",
      "Adding data for VTRS: 475 out of 740\n",
      "Adding data for VICI: 476 out of 740\n",
      "Adding data for V: 477 out of 740\n",
      "Adding data for VMC: 478 out of 740\n",
      "Adding data for WAB: 479 out of 740\n",
      "Adding data for WBA: 480 out of 740\n",
      "Adding data for WMT: 481 out of 740\n",
      "Adding data for WBD: 482 out of 740\n",
      "Adding data for WM: 483 out of 740\n",
      "Adding data for WAT: 484 out of 740\n",
      "Adding data for WEC: 485 out of 740\n",
      "Adding data for WFC: 486 out of 740\n",
      "Adding data for WELL: 487 out of 740\n",
      "Adding data for WST: 488 out of 740\n",
      "Adding data for WDC: 489 out of 740\n",
      "Adding data for WRK: 490 out of 740\n",
      "Adding data for WY: 491 out of 740\n",
      "Adding data for WHR: 492 out of 740\n",
      "Adding data for WMB: 493 out of 740\n",
      "Adding data for WTW: 494 out of 740\n",
      "Adding data for GWW: 495 out of 740\n",
      "Adding data for WYNN: 496 out of 740\n",
      "Adding data for XEL: 497 out of 740\n",
      "Adding data for XYL: 498 out of 740\n",
      "Adding data for YUM: 499 out of 740\n",
      "Adding data for ZBRA: 500 out of 740\n",
      "Adding data for ZBH: 501 out of 740\n",
      "Adding data for ZION: 502 out of 740\n",
      "Adding data for ZTS: 503 out of 740\n",
      "Adding data for ARE.TO: 504 out of 740\n",
      "Adding data for AEM.TO: 505 out of 740\n",
      "Adding data for AC.TO: 506 out of 740\n",
      "Adding data for AGI.TO: 507 out of 740\n",
      "Adding data for AQN.TO: 508 out of 740\n",
      "Adding data for ATD.TO: 509 out of 740\n",
      "Adding data for AP.UN.TO: 510 out of 740\n",
      "Could not download data for AP.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for ALA.TO: 511 out of 740\n",
      "Adding data for AIF.TO: 512 out of 740\n",
      "Adding data for ARX.TO: 513 out of 740\n",
      "Adding data for ATZ.TO: 514 out of 740\n",
      "Adding data for AX.UN.TO: 515 out of 740\n",
      "Could not download data for AX.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for ACO.X.TO: 516 out of 740\n",
      "Could not download data for ACO.X.TO ticker \"('historical')...skipping.\n",
      "Adding data for ATA.TO: 517 out of 740\n",
      "Could not download data for ATA.TO ticker \"('historical')...skipping.\n",
      "Adding data for AUP.TO: 518 out of 740\n",
      "Could not download data for AUP.TO ticker \"('historical')...skipping.\n",
      "Adding data for ACB.TO: 519 out of 740\n",
      "Adding data for BTO.TO: 520 out of 740\n",
      "Adding data for BDGI.TO: 521 out of 740\n",
      "Adding data for BLDP.TO: 522 out of 740\n",
      "Adding data for BMO.TO: 523 out of 740\n",
      "Adding data for BNS.TO: 524 out of 740\n",
      "Adding data for ABX.TO: 525 out of 740\n",
      "Adding data for BHC.TO: 526 out of 740\n",
      "Adding data for BCE.TO: 527 out of 740\n",
      "Adding data for BIR.TO: 528 out of 740\n",
      "Adding data for BB.TO: 529 out of 740\n",
      "Adding data for BEI.UN.TO: 530 out of 740\n",
      "Could not download data for BEI.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for BBD.B.TO: 531 out of 740\n",
      "Could not download data for BBD.B.TO ticker \"('historical')...skipping.\n",
      "Adding data for BLX.TO: 532 out of 740\n",
      "Adding data for BYD.TO: 533 out of 740\n",
      "Adding data for BAM.A.TO: 534 out of 740\n",
      "Could not download data for BAM.A.TO ticker \"('historical')...skipping.\n",
      "Adding data for BBU.UN.TO: 535 out of 740\n",
      "Could not download data for BBU.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for BIP.UN.TO: 536 out of 740\n",
      "Could not download data for BIP.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for BPY.UN.TO: 537 out of 740\n",
      "Could not download data for BPY.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for BEP.UN.TO: 538 out of 740\n",
      "Could not download data for BEP.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for DOO.TO: 539 out of 740\n",
      "Adding data for CAE.TO: 540 out of 740\n",
      "Adding data for CCO.TO: 541 out of 740\n",
      "Adding data for CF.TO: 542 out of 740\n",
      "Adding data for GOOS.TO: 543 out of 740\n",
      "Adding data for CAR.UN.TO: 544 out of 740\n",
      "Could not download data for CAR.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for CM.TO: 545 out of 740\n",
      "Adding data for CNR.TO: 546 out of 740\n",
      "Adding data for CNQ.TO: 547 out of 740\n",
      "Adding data for CP.TO: 548 out of 740\n",
      "Adding data for CTC.A.TO: 549 out of 740\n",
      "Could not download data for CTC.A.TO ticker \"('historical')...skipping.\n",
      "Adding data for CU.TO: 550 out of 740\n",
      "Adding data for CWB.TO: 551 out of 740\n",
      "Adding data for CFP.TO: 552 out of 740\n",
      "Adding data for WEED.TO: 553 out of 740\n",
      "Adding data for CPX.TO: 554 out of 740\n",
      "Adding data for CS.TO: 555 out of 740\n",
      "Adding data for CJT.TO: 556 out of 740\n",
      "Adding data for CAS.TO: 557 out of 740\n",
      "Adding data for CCL.B.TO: 558 out of 740\n",
      "Could not download data for CCL.B.TO ticker \"('historical')...skipping.\n",
      "Adding data for CLS.TO: 559 out of 740\n",
      "Adding data for CVE.TO: 560 out of 740\n",
      "Adding data for CG.TO: 561 out of 740\n",
      "Adding data for GIB.A.TO: 562 out of 740\n",
      "Could not download data for GIB.A.TO ticker \"('historical')...skipping.\n",
      "Adding data for CSH.UN.TO: 563 out of 740\n",
      "Could not download data for CSH.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for CHP.UN.TO: 564 out of 740\n",
      "Could not download data for CHP.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for CIX.TO: 565 out of 740\n",
      "Adding data for CCA.TO: 566 out of 740\n",
      "Adding data for CIGI.TO: 567 out of 740\n",
      "Adding data for CUF.UN.TO: 568 out of 740\n",
      "Could not download data for CUF.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for CSU.TO: 569 out of 740\n",
      "Adding data for CTS.TO: 570 out of 740\n",
      "Adding data for CJR.B.TO: 571 out of 740\n",
      "Could not download data for CJR.B.TO ticker \"('historical')...skipping.\n",
      "Adding data for CPG.TO: 572 out of 740\n",
      "Adding data for CRR.UN.TO: 573 out of 740\n",
      "Could not download data for CRR.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for CRON.TO: 574 out of 740\n",
      "Adding data for CRT.UN.TO: 575 out of 740\n",
      "Could not download data for CRT.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for DML.TO: 576 out of 740\n",
      "Adding data for DSG.TO: 577 out of 740\n",
      "Adding data for DCBO.TO: 578 out of 740\n",
      "Adding data for DOL.TO: 579 out of 740\n",
      "Adding data for DIR.UN.TO: 580 out of 740\n",
      "Could not download data for DIR.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for D.UN.TO: 581 out of 740\n",
      "Could not download data for D.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for DPM.TO: 582 out of 740\n",
      "Adding data for DND.TO: 583 out of 740\n",
      "Adding data for ECN.TO: 584 out of 740\n",
      "Adding data for ELD.TO: 585 out of 740\n",
      "Adding data for EFN.TO: 586 out of 740\n",
      "Adding data for EMA.TO: 587 out of 740\n",
      "Adding data for EMP.A.TO: 588 out of 740\n",
      "Could not download data for EMP.A.TO ticker \"('historical')...skipping.\n",
      "Adding data for ENB.TO: 589 out of 740\n",
      "Adding data for EDR.TO: 590 out of 740\n",
      "Adding data for ERF.TO: 591 out of 740\n",
      "Adding data for ENGH.TO: 592 out of 740\n",
      "Adding data for EQX.TO: 593 out of 740\n",
      "Adding data for EQB.TO: 594 out of 740\n",
      "Adding data for ERO.TO: 595 out of 740\n",
      "Adding data for EIF.TO: 596 out of 740\n",
      "Adding data for FFH.TO: 597 out of 740\n",
      "Adding data for FTT.TO: 598 out of 740\n",
      "Adding data for FCR.UN.TO: 599 out of 740\n",
      "Could not download data for FCR.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for FR.TO: 600 out of 740\n",
      "Adding data for FM.TO: 601 out of 740\n",
      "Adding data for FSV.TO: 602 out of 740\n",
      "Adding data for FTS.TO: 603 out of 740\n",
      "Adding data for FVI.TO: 604 out of 740\n",
      "Adding data for FNV.TO: 605 out of 740\n",
      "Adding data for WN.TO: 606 out of 740\n",
      "Adding data for GFL.TO: 607 out of 740\n",
      "Adding data for GEI.TO: 608 out of 740\n",
      "Adding data for GIL.TO: 609 out of 740\n",
      "Adding data for GSY.TO: 610 out of 740\n",
      "Adding data for GRT.UN.TO: 611 out of 740\n",
      "Could not download data for GRT.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for GWO.TO: 612 out of 740\n",
      "Adding data for HR.UN.TO: 613 out of 740\n",
      "Could not download data for HR.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for HCG.TO: 614 out of 740\n",
      "Could not download data for HCG.TO ticker \"('historical')...skipping.\n",
      "Adding data for HBM.TO: 615 out of 740\n",
      "Adding data for H.TO: 616 out of 740\n",
      "Adding data for IAG.TO: 617 out of 740\n",
      "Adding data for IMG.TO: 618 out of 740\n",
      "Adding data for IGM.TO: 619 out of 740\n",
      "Adding data for IMO.TO: 620 out of 740\n",
      "Adding data for INE.TO: 621 out of 740\n",
      "Adding data for IFC.TO: 622 out of 740\n",
      "Adding data for IPL.TO: 623 out of 740\n",
      "Could not download data for IPL.TO ticker \"('historical')...skipping.\n",
      "Adding data for IFP.TO: 624 out of 740\n",
      "Adding data for IIP.UN.TO: 625 out of 740\n",
      "Could not download data for IIP.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for ITP.TO: 626 out of 740\n",
      "Could not download data for ITP.TO ticker \"('historical')...skipping.\n",
      "Adding data for IVN.TO: 627 out of 740\n",
      "Adding data for JWEL.TO: 628 out of 740\n",
      "Adding data for KNT.TO: 629 out of 740\n",
      "Adding data for KEY.TO: 630 out of 740\n",
      "Adding data for KMP.UN.TO: 631 out of 740\n",
      "Could not download data for KMP.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for KXS.TO: 632 out of 740\n",
      "Adding data for K.TO: 633 out of 740\n",
      "Adding data for KL.TO: 634 out of 740\n",
      "Could not download data for KL.TO ticker \"('historical')...skipping.\n",
      "Adding data for LIF.TO: 635 out of 740\n",
      "Adding data for LB.TO: 636 out of 740\n",
      "Adding data for LWRK.TO: 637 out of 740\n",
      "Could not download data for LWRK.TO ticker \"('historical')...skipping.\n",
      "Adding data for LSPD.TO: 638 out of 740\n",
      "Adding data for LNR.TO: 639 out of 740\n",
      "Adding data for LAC.TO: 640 out of 740\n",
      "Adding data for L.TO: 641 out of 740\n",
      "Adding data for LUN.TO: 642 out of 740\n",
      "Adding data for MAG.TO: 643 out of 740\n",
      "Adding data for MG.TO: 644 out of 740\n",
      "Adding data for MFC.TO: 645 out of 740\n",
      "Adding data for MFI.TO: 646 out of 740\n",
      "Adding data for MRE.TO: 647 out of 740\n",
      "Adding data for MEG.TO: 648 out of 740\n",
      "Adding data for MX.TO: 649 out of 740\n",
      "Adding data for MRU.TO: 650 out of 740\n",
      "Adding data for MTY.TO: 651 out of 740\n",
      "Adding data for MTL.TO: 652 out of 740\n",
      "Adding data for NA.TO: 653 out of 740\n",
      "Adding data for NGD.TO: 654 out of 740\n",
      "Adding data for NXE.TO: 655 out of 740\n",
      "Adding data for NFI.TO: 656 out of 740\n",
      "Adding data for NPI.TO: 657 out of 740\n",
      "Adding data for NWH.UN.TO: 658 out of 740\n",
      "Could not download data for NWH.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for NG.TO: 659 out of 740\n",
      "Adding data for NTR.TO: 660 out of 740\n",
      "Adding data for NVEI.TO: 661 out of 740\n",
      "Adding data for OGC.TO: 662 out of 740\n",
      "Adding data for ONEX.TO: 663 out of 740\n",
      "Adding data for OTEX.TO: 664 out of 740\n",
      "Adding data for OGI.TO: 665 out of 740\n",
      "Adding data for OR.TO: 666 out of 740\n",
      "Adding data for OSK.TO: 667 out of 740\n",
      "Adding data for PAAS.TO: 668 out of 740\n",
      "Adding data for PXT.TO: 669 out of 740\n",
      "Adding data for PKI.TO: 670 out of 740\n",
      "Adding data for PPL.TO: 671 out of 740\n",
      "Adding data for POW.TO: 672 out of 740\n",
      "Adding data for PSK.TO: 673 out of 740\n",
      "Adding data for PBH.TO: 674 out of 740\n",
      "Adding data for PVG.TO: 675 out of 740\n",
      "Could not download data for PVG.TO ticker \"('historical')...skipping.\n",
      "Adding data for PRMW.TO: 676 out of 740\n",
      "Adding data for QBR.B.TO: 677 out of 740\n",
      "Could not download data for QBR.B.TO ticker \"('historical')...skipping.\n",
      "Adding data for REAL.TO: 678 out of 740\n",
      "Adding data for QSR.TO: 679 out of 740\n",
      "Adding data for RCH.TO: 680 out of 740\n",
      "Adding data for REI.UN.TO: 681 out of 740\n",
      "Could not download data for REI.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for RBA.TO: 682 out of 740\n",
      "Adding data for RCI.B.TO: 683 out of 740\n",
      "Could not download data for RCI.B.TO ticker \"('historical')...skipping.\n",
      "Adding data for RY.TO: 684 out of 740\n",
      "Adding data for RUS.TO: 685 out of 740\n",
      "Adding data for SSL.TO: 686 out of 740\n",
      "Adding data for SAP.TO: 687 out of 740\n",
      "Adding data for SEA.TO: 688 out of 740\n",
      "Adding data for SJR.B.TO: 689 out of 740\n",
      "Could not download data for SJR.B.TO ticker \"('historical')...skipping.\n",
      "Adding data for SHOP.TO: 690 out of 740\n",
      "Adding data for SIA.TO: 691 out of 740\n",
      "Adding data for SVM.TO: 692 out of 740\n",
      "Adding data for SIL.TO: 693 out of 740\n",
      "Adding data for ZZZ.TO: 694 out of 740\n",
      "Adding data for SRU.UN.TO: 695 out of 740\n",
      "Could not download data for SRU.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for SNC.TO: 696 out of 740\n",
      "Could not download data for SNC.TO ticker \"('historical')...skipping.\n",
      "Adding data for TOY.TO: 697 out of 740\n",
      "Adding data for SII.TO: 698 out of 740\n",
      "Adding data for SSRM.TO: 699 out of 740\n",
      "Adding data for STN.TO: 700 out of 740\n",
      "Adding data for STLC.TO: 701 out of 740\n",
      "Adding data for SJ.TO: 702 out of 740\n",
      "Adding data for SMU.UN.TO: 703 out of 740\n",
      "Could not download data for SMU.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for SLF.TO: 704 out of 740\n",
      "Adding data for SU.TO: 705 out of 740\n",
      "Adding data for SOY.TO: 706 out of 740\n",
      "Adding data for SPB.TO: 707 out of 740\n",
      "Adding data for TRP.TO: 708 out of 740\n",
      "Adding data for TECK.B.TO: 709 out of 740\n",
      "Could not download data for TECK.B.TO ticker \"('historical')...skipping.\n",
      "Adding data for T.TO: 710 out of 740\n",
      "Adding data for TIXT.TO: 711 out of 740\n",
      "Adding data for TFII.TO: 712 out of 740\n",
      "Adding data for NWC.TO: 713 out of 740\n",
      "Adding data for TRI.TO: 714 out of 740\n",
      "Adding data for TLRY.TO: 715 out of 740\n",
      "Adding data for X.TO: 716 out of 740\n",
      "Adding data for TXG.TO: 717 out of 740\n",
      "Adding data for TIH.TO: 718 out of 740\n",
      "Adding data for TD.TO: 719 out of 740\n",
      "Adding data for TOU.TO: 720 out of 740\n",
      "Adding data for TA.TO: 721 out of 740\n",
      "Adding data for RNW.TO: 722 out of 740\n",
      "Could not download data for RNW.TO ticker \"('historical')...skipping.\n",
      "Adding data for TCL.A.TO: 723 out of 740\n",
      "Could not download data for TCL.A.TO ticker \"('historical')...skipping.\n",
      "Adding data for TCN.TO: 724 out of 740\n",
      "Adding data for TSU.TO: 725 out of 740\n",
      "Adding data for TRQ.TO: 726 out of 740\n",
      "Could not download data for TRQ.TO ticker \"('historical')...skipping.\n",
      "Adding data for VET.TO: 727 out of 740\n",
      "Adding data for VFF.TO: 728 out of 740\n",
      "Could not download data for VFF.TO ticker \"('historical')...skipping.\n",
      "Adding data for WCN.TO: 729 out of 740\n",
      "Adding data for WELL.TO: 730 out of 740\n",
      "Adding data for WDO.TO: 731 out of 740\n",
      "Adding data for WFG.TO: 732 out of 740\n",
      "Adding data for WPRT.TO: 733 out of 740\n",
      "Adding data for WTE.TO: 734 out of 740\n",
      "Adding data for WPM.TO: 735 out of 740\n",
      "Adding data for WCP.TO: 736 out of 740\n",
      "Adding data for WPK.TO: 737 out of 740\n",
      "Adding data for WIR.UN.TO: 738 out of 740\n",
      "Could not download data for WIR.UN.TO ticker \"('historical')...skipping.\n",
      "Adding data for WSP.TO: 739 out of 740\n",
      "Adding data for YRI.TO: 740 out of 740\n",
      "Could not download data for YRI.TO ticker \"('historical')...skipping.\n"
     ]
    }
   ],
   "source": [
    "TICKER_COUNT=740\n",
    "\n",
    "today = date.today()-DateOffset(days=1)\n",
    "#from_date='2019-12-03'\n",
    "to=today-DateOffset(days=4)\n",
    "from_date=to.strftime(\"%Y-%m-%d\")\n",
    "to_date=today.strftime(\"%Y-%m-%d\")\n",
    "to_date=today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "#to_date=today\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    # Loop over the tickers and insert the daily historical\n",
    "    # data into the database\n",
    "    tickers = obtain_list_of_db_tickers()[:TICKER_COUNT]\n",
    "    lentickers = len(tickers)\n",
    "    for i, t in enumerate(tickers):\n",
    "        try:\n",
    "            print(\n",
    "            \"Adding data for %s: %s out of %s\" %\n",
    "            (t[1], i+1, lentickers)\n",
    "            )\n",
    "            av_data = stock_data(t[1],from_date,to_date)\n",
    "            insert_daily_data_into_db(t[0], av_data)\n",
    "        \n",
    "        except:\n",
    "            print(\"Unable to add data for %s: %s out of %s\" %\n",
    "            (t[1], i+1, lentickers)\n",
    "            )\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4c626-84ab-4a08-af45-ced6d004844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ticker lookup tool\n",
    "def ticker_lookup(symbol,exchange):\n",
    "    api_url = (f\"https://financialmodelingprep.com/api/v3/search?query={symbol}\"\n",
    "               f\"&limit=10&exchange={exchange}&apikey={apikey}\")\n",
    "    #Fetching data\n",
    "    results=requests.get(api_url)\n",
    "    results= results.json()\n",
    "    \n",
    "    return results[:]#[0]['symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dcc93f-759a-4643-b831-1f6c439b41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_lookup('LMND','')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
